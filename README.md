# financial_chatbot
# ğŸ§  Chatbot using LLaMA-2, LangChain & Streamlit

This project is an interactive chatbot built with **Streamlit**, powered by **LLaMA-2** and **LangChain**. It allows users to ask questions based on the content of local PDF documents and get intelligent responses using retrieval-augmented generation (RAG).

> âš¡ Ask anything related to the content in your PDF files. Useful for personal assistants, document Q&A, or domain-specific bots (e.g., health, law, research).

---

## Features

- ğŸ“ Loads and processes all PDFs in the `data/` directory.
- ğŸ§© Splits text into manageable chunks using recursive splitting.
- ğŸ¤— Uses `sentence-transformers/all-MiniLM-L6-v2` for semantic search.
- ğŸ” FAISS vector store for fast document retrieval.
- ğŸ§  LLaMA-2 7B chatbot via `CTransformers` (quantized `.ggmlv3` model).
- ğŸ’¬ Conversational memory with contextual replies.
- ğŸŒ Streamlit-based UI with persistent chat history.

---

## Requirements

Install dependencies via:

```bash
pip install -r requirements.txt

## Folder Structure
.
â”œâ”€â”€ app.py              # Main Streamlit app
â”œâ”€â”€ data/               # Folder to store all your PDF documents
â”œâ”€â”€ models/             # (Optional) Folder to store .bin model files like llama-2-7b
â””â”€â”€ README.md

## Run the app
streamlit run app.py
